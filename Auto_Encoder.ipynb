{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da84024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, encoding_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 1024), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),  \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, encoding_size),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder layers\n",
    "    \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(encoding_size, 128), \n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, input_size),\n",
    "            torch.nn.Sigmoid()  # Use Sigmoid activation for the output layer\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "class CompactCNN(torch.nn.Module):\n",
    "    def __init__(self, classes=2, channels=32, kernelLength=15, encoding_size=64):\n",
    "        super(CompactCNN, self).__init__()\n",
    "        self.kernelLength = kernelLength\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, channels, (1, kernelLength))\n",
    "        self.batch1 = Batchlayer(channels)\n",
    "        self.elu1 = torch.nn.ELU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.7)\n",
    "\n",
    "        # GAP and Fully Connected Layer\n",
    "        self.fc = torch.nn.Linear(channels, classes)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputdata):\n",
    "        intermediate = self.conv1(inputdata)\n",
    "        intermediate = self.batch1(intermediate)\n",
    "        intermediate = self.elu1(intermediate)\n",
    "        intermediate = self.dropout1(intermediate)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        intermediate = torch.nn.functional.adaptive_avg_pool2d(intermediate, (1, 1))\n",
    "\n",
    "        # Flatten the output before fully connected layer\n",
    "        intermediate = intermediate.view(intermediate.size(0), -1)\n",
    "\n",
    "        intermediate = self.fc(intermediate)\n",
    "        output = self.softmax(intermediate)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Batchlayer(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Batchlayer, self).__init__()\n",
    "        self.gamma = torch.nn.Parameter(torch.Tensor(1, dim, 1, 1))\n",
    "        self.beta = torch.nn.Parameter(torch.Tensor(1, dim, 1, 1))\n",
    "        self.gamma.data.uniform_(-0.1, 0.1)\n",
    "        self.beta.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        data = normalizelayer(input)\n",
    "        gammamatrix = self.gamma.expand(int(data.size(0)), int(data.size(1)), int(data.size(2)), int(data.size(3)))\n",
    "        betamatrix = self.beta.expand(int(data.size(0)), int(data.size(1)), int(data.size(2)), int(data.size(3)))\n",
    "\n",
    "        return data * gammamatrix + betamatrix\n",
    "\n",
    "class CompactCNNWithAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, classes=2, channels=32, kernelLength=125, sampleLength=1751, encoding_size=64):\n",
    "        super(CompactCNNWithAutoencoder, self).__init__()\n",
    "        self.autoencoder = Autoencoder(sampleLength, encoding_size)\n",
    "        self.compact_cnn = CompactCNN(classes, channels, kernelLength, encoding_size)  # Use encoding_size instead of sampleLength\n",
    "\n",
    "    def forward(self, inputdata):\n",
    "        encoded_data = self.autoencoder(inputdata.view(inputdata.size(0), -1))\n",
    "        # Use the encoded features directly, no need to reconstruct\n",
    "        \n",
    "        output = self.compact_cnn(encoded_data.view(encoded_data.size(0), 1, 1, -1))\n",
    "        return output\n",
    "\n",
    "def normalizelayer(data):\n",
    "    eps = 1e-05\n",
    "    a_mean = data - torch.mean(data, [0, 2, 3], True).expand(int(data.size(0)), int(data.size(1)), int(data.size(2)),\n",
    "                                                              int(data.size(3)))\n",
    "    b = torch.div(a_mean, torch.sqrt(torch.mean((a_mean) ** 2, [0, 2, 3], True) + eps).expand(int(data.size(0)),\n",
    "                                                                                                int(data.size(1)),\n",
    "                                                                                                int(data.size(2)),\n",
    "                                                                                                int(data.size(3))))\n",
    "\n",
    "    return b\n",
    "\n",
    "def get_encoded_features(data, autoencoder_model):\n",
    "    with torch.no_grad():\n",
    "        data_tensor = torch.FloatTensor(data)\n",
    "        encoded_data = autoencoder_model(data_tensor.view(data_tensor.size(0), -1))\n",
    "    return encoded_data\n",
    "\n",
    "def run():\n",
    "    lr_autoencoder = 1e-2\n",
    "    lr_compactcnn = 1e-3\n",
    "    batch_size = 32\n",
    "    n_epoch_autoencoder = 10\n",
    "    n_epoch_compactcnn = 10\n",
    "\n",
    "    indices = [128, 21, 22, 32, 23, 10, 27, 12, 44, 35, 46, 36, 57, 51, 66, 69, 8, 2, 121, 123, 116, 111, 107, 103, 97, 86,\n",
    "               95, 91, 61, 76, 82, 74]\n",
    "\n",
    "    xdata = np.load(\"path/eeg_data.npy\")\n",
    "    ydata = np.load(\"path/labels.npy\")\n",
    "\n",
    "    reduced_features_list = []  # to store reduced features for each index\n",
    "\n",
    "    for i in indices:\n",
    "        x_index = xdata[:, i - 1, :]  # Extracting data for a specific index i\n",
    "        x_index = x_index.reshape(x_index.shape[0], 1, 1, 1751)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_index, ydata, test_size=0.2, random_state=42)\n",
    "\n",
    "        x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "        x_val_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "        val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Autoencoder Training\n",
    "        autoencoder_cnn = CompactCNNWithAutoencoder(classes=2, channels=32, kernelLength=125, sampleLength=1751, encoding_size=64)\n",
    "        optimizer_autoencoder = optim.Adam(autoencoder_cnn.autoencoder.parameters(), lr=lr_autoencoder)\n",
    "        loss_autoencoder = torch.nn.MSELoss()\n",
    "        threshold = 0.03\n",
    "        for epoch in range(n_epoch_autoencoder):\n",
    "            total_loss = 0.0\n",
    "            total_samples = 0\n",
    "            \n",
    "\n",
    "            for j, data in enumerate(train_loader, 0):\n",
    "                inputs, _ = data\n",
    "                autoencoder_cnn.autoencoder.zero_grad()\n",
    "                autoencoder_cnn.autoencoder.train()\n",
    "\n",
    "                # Encoding\n",
    "                encoded_data = autoencoder_cnn.autoencoder.encoder(inputs.view(inputs.size(0), -1))\n",
    "\n",
    "                # Decoding\n",
    "                reconstructed_data = autoencoder_cnn.autoencoder.decoder(encoded_data)\n",
    "\n",
    "                # Loss calculation\n",
    "                err_autoencoder = loss_autoencoder(reconstructed_data, inputs)\n",
    "                err_autoencoder.backward()\n",
    "                optimizer_autoencoder.step()\n",
    "\n",
    "                \n",
    "                total_loss += err_autoencoder.item()\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "                diff = torch.abs(reconstructed_data - inputs)\n",
    "                mse_per_sample = torch.mean(diff, dim=(1, 2, 3))\n",
    "                \n",
    "            # Print average MSE and accuracy for the epoch\n",
    "            average_loss = total_loss / total_samples\n",
    "            print(f\"Epoch {epoch + 1}, Average MSE Loss: {average_loss:.4f}\")\n",
    "\n",
    "        # Get encoded features for training and validation data\n",
    "        autoencoder_cnn.autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            x_train_encoded = autoencoder_cnn.autoencoder.encoder(torch.tensor(x_train, dtype=torch.float32).view(x_train.shape[0], -1)).numpy()\n",
    "            x_val_encoded = autoencoder_cnn.autoencoder.encoder(torch.tensor(x_test, dtype=torch.float32).view(x_test.shape[0], -1)).numpy()\n",
    "\n",
    "        reduced_features_list.append((x_train_encoded, x_val_encoded))\n",
    "\n",
    "\n",
    "        # CompactCNN Training with Encoded Features\n",
    "        x_train_encoded = x_train_encoded.reshape(x_train_encoded.shape[0], 1, 1, -1)\n",
    "        x_val_encoded = x_val_encoded.reshape(x_val_encoded.shape[0], 1, 1, -1)\n",
    "\n",
    "        x_train_tensor_encoded = torch.tensor(x_train_encoded, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "        x_val_tensor_encoded = torch.tensor(x_val_encoded, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "        \n",
    "\n",
    "        \n",
    "        train_dataset_encoded = TensorDataset(x_train_tensor_encoded, y_train_tensor)\n",
    "        val_dataset_encoded = TensorDataset(x_val_tensor_encoded, y_val_tensor)\n",
    "\n",
    "        train_loader_encoded = DataLoader(train_dataset_encoded, batch_size=batch_size, shuffle=True)\n",
    "        val_loader_encoded = DataLoader(val_dataset_encoded, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        compactcnn_model = CompactCNN(classes=2, channels=32, kernelLength=15, encoding_size=64) \n",
    "        optimizer_compactcnn = optim.Adam(compactcnn_model.parameters(), lr=lr_compactcnn)\n",
    "        loss_compactcnn = torch.nn.NLLLoss()\n",
    "\n",
    "\n",
    "        for epoch in range(n_epoch_compactcnn):\n",
    "            for j, data in enumerate(train_loader_encoded, 0):\n",
    "                inputs, labels = data\n",
    "                compactcnn_model.zero_grad()\n",
    "                compactcnn_model.train()\n",
    "                class_output = compactcnn_model(inputs)\n",
    "                err_s_label = loss_compactcnn(class_output, labels)\n",
    "                err = err_s_label\n",
    "                err.backward()\n",
    "                optimizer_compactcnn.step()\n",
    "\n",
    "        # Evaluation\n",
    "        compactcnn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_val_tensor_encoded = torch.tensor(x_val_encoded, dtype=torch.float32)\n",
    "            answer = compactcnn_model(x_val_tensor_encoded)\n",
    "            probs = answer.cpu().numpy()\n",
    "            preds = probs.argmax(axis=-1)\n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            print(f\"Accuracy (Index {i}): {acc:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
